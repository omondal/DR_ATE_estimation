{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doubly Robust Average Treatment Effects Estimation with Multiple Treatments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction and Problem Statement"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to evaluate the impact of a government sponsored job training program on individual earnings. Training can take multiple forms - classroom training, on the job vocational training, or a mix of the two. A randomized trial is conducted wherein applicants were assigned to either a treatment arm where they received some form of training under the program, or a control arm where they didn't. Therefore, there were four total \"arms\" in the experiment. As a data analyst, our objective is to use the data from this experiment to analyze if training was actually helpful. \n",
    "\n",
    "The Job Training Partnership Act (JTPA) Study from the late 1980's is a widely cited experiment which did exactly this. There is one major caveat - applicants to the program were not randomly assigned to one of four treatment arms. Rather, an applicant who was deemed eligible for help under the program was first evaluated by a case worker who determined the best training strategy for them - one of classroom, on the job (OJT) or mixed training. After this decision was made for all eligible applicants, the pool of agents was randomly split into a treatment arm and control arm with probabilities 2/3 and 1/3, respectively. Therefore, even though assignment to *some* form of training was random, assignment to any *particular* training regime was not. \n",
    "\n",
    "The objective of this notebook is to describe a strategy to estimate the possible gains from each of the three forms of training. This will be done using the potential outcomes framework - namely, if $Y(d)$ denotes an individual's earnings after receiving treatment $d$ where $d\\in \\{\\text{classroom}, \\text{OJT}, \\text{mixed}\\}$, then we are interested in the average difference in earnings, relative to no training (represented as $d= 0$) i.e.\n",
    "\\begin{align}\n",
    "\\mathbb{E}[Y(d) - Y(0)], \\hspace{3mm}\\text{for }d\\in \\{\\text{classroom}, \\text{OTJ}, \\text{mixed}\\},\n",
    "\\end{align}\n",
    "where $Y(0)$ represents the earnings under no treatment. The difference above is the average treatment effect for treatment $d$ or $ATE(d)$ and is considered a causal object i.e. if $ATE(d)$ is negative, we may (very roughly) say that the on average lower than baseline earnings of people who were given training $d$ was *caused* by training $d$. \n",
    "\n",
    "Under appropriate assumptions which are not covered here, if we are presented with data from a randomized experiment $(Y_i, X_i, D_i)$ for $i=1, ...,n$ where $Y_i$ denotes earnnings of agent $i$, $X_i$ is a vector of characteristics prior to assignment to a treatment arm, and $D_i$ denotes their assigned treatment arm, then the following is a doubly robust estimator for $\\mathbb{E}[Y(d)]$:\n",
    "\\begin{align}\n",
    "\\frac{1}{n} \\sum_{i=1}^n \\frac{Y_i - \\mu_d(X_i)}{p_d(X_i)}\\cdot \\mathrm{1}\\{D_i = d\\} + \\mu_d(X_i),\n",
    "\\end{align}\n",
    "where the objects $\\mu_d, p_d$ represent the following conditional mean functions:\n",
    "\\begin{align}\n",
    "\\mu_d(x) & = \\mathbb{E}[Y_i(d) \\mid X_i = x]\\\\\n",
    "p_d(x) & = \\mathbb{P}(D_i = d \\mid X_i = x).\n",
    "\\end{align}\n",
    "In finite samples, we don't know the functions $\\mu_d, p_d$ and must therefore estimate them as $\\hat{\\mu}_d, \\hat{p}_d$. The estimator above is called doubly robust because with a large enough dataset, it approximately equals $\\mathbb{E}[Y(d)]$ if either $\\mu_d$ or $p_d$ are poorly estimated. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a doubly robust specification has two main advantages. First of all, it can be shown that if we have data for many participants (i.e. $n$ is large), the doubly robust estimator shown above will lead to an extremely precise estimate of the average treatment effect of training $d$, $ATE(d)$. Indeed, out of many sensible ways to measure the causal impact of training, the doubly robust estimator will offer the most precise estimate, in the sense of having the lowest possible variance (or spread). While interesting, low variance is not the main objective of the exercise described here. Rather, it is the second advantage of doubly robust estimators which is more important.\n",
    "\n",
    "Recall that in order to actually use the doubly robust estimator, we first need to form estimates $\\hat{\\mu}_d, \\hat{p}_d$. Modern machine learning methods offer high quality estimates of precisely this form. In practice though, it was noticed that simply estimating $\\hat{\\mu}_d$ using a modern ML method (LASSO, say) and estimating $ATE(d)$ naively as,\n",
    "\\begin{align}\n",
    "\\frac{1}{n}\\sum_{i=1}^n\\hat{\\mu}_d(X_i) - \\hat{\\mu}_0(X_i),\n",
    "\\end{align}\n",
    "would perform poorly and suffer from high variance and bias regardless of ML best practices, unless data sets were extremely large. The doubly robust estimator, combined with a form of cross fitted regression estimation delivers a superior estimate of $ATE(d)$. The rest of this notebook will now describe the exact steps needed to compute reliable estimates of $ATE(d)$, and then implement these steps."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation Strategy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we have a dataset given by $(Y_i, X_i, D_i)_{i=1}^n$. For any $d$, we calculate an estimate for $\\mathbb{E}[Y(d)]$ using the following steps:\n",
    "\n",
    "1. Randomly partition the observations ${1,2,...,n}$ into folds $(I_l)_{l=1}^L$ of approximately equal size. Here $I_l$ is a list of indices for obervations in fold $l$. Let $I_l^c$ denote all observations not in fold $l$.\n",
    "2. For each fold $l$, esimate $\\hat{\\mu}_d^l, \\hat{p}_d^l$ using observations in $I_l^c$. Exactly how these are estimated is discussed below.\n",
    "3. After estimation is done for all folds, define the following estimate:  \n",
    "\\begin{align}\n",
    "\\hat{\\mathbb{E}}[Y_i(d)] = \\frac{1}{n}\\sum_{l=i}^L \\sum_{i\\in I_l}\\frac{Y_i - \\hat{\\mu}^l_d(X_i)}{\\hat{p}^l_d(X_i)}\\cdot \\mathrm{1}\\{D_i = d\\} + \\hat{\\mu}^l_d(X_i)\n",
    "\\end{align}\n",
    "4. Define the estimated casual impact of training $d$ as:\n",
    "\\begin{align}\n",
    "\\hat{ATE}(d) = \\hat{\\mathbb{E}}[Y_i(d)] - \\hat{\\mathbb{E}}[Y_i(0)].\n",
    "\\end{align}\n",
    "\n",
    "The above steps describe the cross-fitting process needed to reliably estimate our causal impacts of interest. The intermediate estimates $\\hat{\\mu}^l_d$ and $\\hat{p}^l_d$ for each of the folds will be derived using appropriate machine learning or high dimensional methods. The primary difference between these two functions is that $\\hat{\\mu}^l_d$ should be the output of a regression algorithm (e.g. LASSO, random forests), while $\\hat{p}_d^l$ should be the output of a multi-arm classification algorithm (e.g. multinomial penalized logistic regression). We can now begin implementing the estimation strategy outlined here. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "#Include modeling tools.\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, Lasso, Ridge, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score, accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading Dataset and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11204, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jtpa = pd.read_csv('jtpa_reasons_outcome.csv', index_col='recid')\n",
    "vars_to_keep = ['assignmt', 'sex', 'class_tr', 'ojt_jsa', 'oth_serv', 'age' , 'earnings', 'prevearn', 'married', 'pbhous', 'wkless13', 'bfeduca']\n",
    "jtpa_keep = jtpa[vars_to_keep]\n",
    "\n",
    "#Construct recommended training variable\n",
    "rec_training = [\"\" for i in range(jtpa_keep.shape[0])]\n",
    "for i in range(jtpa_keep.shape[0]):\n",
    "    if jtpa_keep.class_tr.iloc[i] ==1:\n",
    "        rec_training[i] = 'classroom'\n",
    "    elif jtpa_keep.ojt_jsa.iloc[i] ==1:\n",
    "        rec_training[i] = 'OJT'\n",
    "    elif jtpa_keep.oth_serv.iloc[i]==1:\n",
    "        rec_training[i] = 'other' \n",
    "\n",
    "jtpa_keep.insert(jtpa_keep.shape[1], 'recommended_training', rec_training, True)\n",
    "#Drop original variables\n",
    "jtpa_keep = jtpa_keep.drop(['class_tr', 'ojt_jsa', 'oth_serv'], axis = 1)\n",
    "\n",
    "#Shape of dataset\n",
    "jtpa_keep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assignmt</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>earnings</th>\n",
       "      <th>prevearn</th>\n",
       "      <th>married</th>\n",
       "      <th>pbhous</th>\n",
       "      <th>wkless13</th>\n",
       "      <th>bfeduca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11204.00</td>\n",
       "      <td>11204.00</td>\n",
       "      <td>11204.00</td>\n",
       "      <td>11204.00</td>\n",
       "      <td>11204.00</td>\n",
       "      <td>11204.00</td>\n",
       "      <td>11204.00</td>\n",
       "      <td>11204.00</td>\n",
       "      <td>11204.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.46</td>\n",
       "      <td>33.14</td>\n",
       "      <td>15815.29</td>\n",
       "      <td>3202.31</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.46</td>\n",
       "      <td>13.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.64</td>\n",
       "      <td>16767.05</td>\n",
       "      <td>3901.45</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.47</td>\n",
       "      <td>11.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>1929.75</td>\n",
       "      <td>98.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>11010.00</td>\n",
       "      <td>2444.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.41</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>38.00</td>\n",
       "      <td>24798.25</td>\n",
       "      <td>4103.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>78.00</td>\n",
       "      <td>155760.00</td>\n",
       "      <td>63000.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       assignmt       sex       age   earnings  prevearn   married    pbhous  \\\n",
       "count  11204.00  11204.00  11204.00   11204.00  11204.00  11204.00  11204.00   \n",
       "mean       0.67      0.46     33.14   15815.29   3202.31      0.28      0.09   \n",
       "std        0.47      0.50      9.64   16767.05   3901.45      0.43      0.28   \n",
       "min        0.00      0.00     22.00       0.00      0.00      0.00      0.00   \n",
       "25%        0.00      0.00     26.00    1929.75     98.00      0.00      0.00   \n",
       "50%        1.00      0.00     31.00   11010.00   2444.66      0.00      0.00   \n",
       "75%        1.00      1.00     38.00   24798.25   4103.91      1.00      0.00   \n",
       "max        1.00      1.00     78.00  155760.00  63000.00      1.00      1.00   \n",
       "\n",
       "       wkless13   bfeduca  \n",
       "count  11204.00  11204.00  \n",
       "mean       0.46     13.09  \n",
       "std        0.47     11.61  \n",
       "min        0.00      7.00  \n",
       "25%        0.00     11.00  \n",
       "50%        0.41     12.00  \n",
       "75%        1.00     12.00  \n",
       "max        1.00     99.00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jtpa_keep.describe().round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some missing values and data issues. For example, the column `bfeduca` records an applicants education (in years) at the time they applied to the JTPA for help. The value 99 corresponds to a missing value. An applicant's education level is typically highly correlated with their ability to benefit from training - so a missing value severely reduces the informativeness of such an observation and may be removed, as long as there aren't too many missing values. \n",
    "\n",
    "It is also important to check for clear errors - for example, if the binary variables in the dataset have entries which are neither `0` not `1`. The following code block replaces missing values and data errors in the variables with `NaN`. Observations with any missing values are then dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of missing values generated: \n",
      "assignmt                   0\n",
      "sex                        0\n",
      "age                        0\n",
      "earnings                   0\n",
      "prevearn                   0\n",
      "married                  764\n",
      "pbhous                   229\n",
      "wkless13                1178\n",
      "bfeduca                  196\n",
      "recommended_training       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9191"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Missing values in applicant education levels.\n",
    "jtpa_keep.bfeduca.replace(99, np.nan, inplace=True)\n",
    "\n",
    "#Replace non-0,1 values in binary variables with NaN\n",
    "binary_vars = [e for e in list(jtpa_keep.columns) if e not in ['age', 'earnings', 'prevearn', 'bfeduca', 'recommended_training']]\n",
    "for v in binary_vars:\n",
    "    #No. of errors\n",
    "    errors = ~((jtpa_keep[v]==0)|(jtpa_keep[v]==1))\n",
    "    if np.sum(errors)>=1:\n",
    "        jtpa_keep.loc[errors, v] = np.nan\n",
    "\n",
    "print('No. of missing values generated: ')\n",
    "print(jtpa_keep.isnull().sum())\n",
    "\n",
    "#Drop observations with missing data\n",
    "jtpa_keep = jtpa_keep.dropna(axis = 0) \n",
    "#How many observations were lost? Originally, we had 11204 obs. Now it is 11008.\n",
    "jtpa_keep.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>earnings</th>\n",
       "      <th>prevearn</th>\n",
       "      <th>bfeduca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9191.00</td>\n",
       "      <td>9191.00</td>\n",
       "      <td>9191.00</td>\n",
       "      <td>9191.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33.01</td>\n",
       "      <td>16.47</td>\n",
       "      <td>3.32</td>\n",
       "      <td>11.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.63</td>\n",
       "      <td>17.19</td>\n",
       "      <td>4.10</td>\n",
       "      <td>1.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>22.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.00</td>\n",
       "      <td>2.23</td>\n",
       "      <td>0.04</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31.00</td>\n",
       "      <td>11.64</td>\n",
       "      <td>2.40</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.00</td>\n",
       "      <td>25.72</td>\n",
       "      <td>4.80</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>78.00</td>\n",
       "      <td>155.76</td>\n",
       "      <td>63.00</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           age  earnings  prevearn  bfeduca\n",
       "count  9191.00   9191.00   9191.00  9191.00\n",
       "mean     33.01     16.47      3.32    11.63\n",
       "std       9.63     17.19      4.10     1.85\n",
       "min      22.00      0.00      0.00     7.00\n",
       "25%      26.00      2.23      0.04    11.00\n",
       "50%      31.00     11.64      2.40    12.00\n",
       "75%      38.00     25.72      4.80    12.00\n",
       "max      78.00    155.76     63.00    18.00"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change some binary variables to categorical for better visualization\n",
    "jtpa_keep['sex'].replace([0,1],['Female', 'Male'], inplace = True)\n",
    "jtpa_keep['assignmt'].replace([0,1],['Control', 'Treatment'], inplace = True)\n",
    "jtpa_keep['pbhous'].replace([0,1],['No', 'Yes'], inplace = True)\n",
    "jtpa_keep['married'].replace([0,1],['Not married', 'Married'], inplace = True)\n",
    "jtpa_keep['wkless13'].replace([0,1],['Did not work', 'Worked'], inplace = True)\n",
    "#jtpa_keep['training'].replace([0,1],['No training', 'Trained'], inplace = True)\n",
    "\n",
    "\n",
    "#Transfrom post-training phase earnings and earnings prior to assignment to be in thousands ('000s).\n",
    "jtpa_keep['earnings']  = jtpa['earnings']/1000\n",
    "jtpa_keep['prevearn']  = jtpa['prevearn']/1000\n",
    "\n",
    "jtpa_keep.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assignmt</th>\n",
       "      <th>sex</th>\n",
       "      <th>married</th>\n",
       "      <th>pbhous</th>\n",
       "      <th>wkless13</th>\n",
       "      <th>recommended_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9191</td>\n",
       "      <td>9191</td>\n",
       "      <td>9191</td>\n",
       "      <td>9191</td>\n",
       "      <td>9191</td>\n",
       "      <td>9191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Treatment</td>\n",
       "      <td>Female</td>\n",
       "      <td>Not married</td>\n",
       "      <td>No</td>\n",
       "      <td>Did not work</td>\n",
       "      <td>OJT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6124</td>\n",
       "      <td>4842</td>\n",
       "      <td>6561</td>\n",
       "      <td>8413</td>\n",
       "      <td>5057</td>\n",
       "      <td>4066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         assignmt     sex      married pbhous      wkless13  \\\n",
       "count        9191    9191         9191   9191          9191   \n",
       "unique          2       2            2      2             2   \n",
       "top     Treatment  Female  Not married     No  Did not work   \n",
       "freq         6124    4842         6561   8413          5057   \n",
       "\n",
       "       recommended_training  \n",
       "count                  9191  \n",
       "unique                    3  \n",
       "top                     OJT  \n",
       "freq                   4066  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jtpa_keep.describe(include = ['object'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, remove some outliers in data for earnings of an applicant in the year prior to treatment assignment (`prevearn`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "jtpa_keep = jtpa_keep[(np.abs(stats.zscore(jtpa_keep.prevearn))<3)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary continuously distributed covariate/feature is `prevearn`. In what follows, we will first augment the set of explanatory variables with raised powers of `prevearn`. We till then augment with interactions with the binary variables in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original no. of features:  18\n",
      "Interactions and higher order terms:  3725\n"
     ]
    }
   ],
   "source": [
    "#Set of features in dataset.\n",
    "jtpa_features_augmented= jtpa_keep.drop(['earnings'], axis = 1).copy()\n",
    "\n",
    "#Create Dummies for the recommended training\n",
    "jtpa_features_augmented = pd.get_dummies(jtpa_features_augmented)\n",
    "\n",
    "#Add powers of 'prevearn'\n",
    "for n in range(2, 4):\n",
    "    jtpa_features_augmented['prevearn_{}'.format(n)] = jtpa_keep.prevearn**n\n",
    "\n",
    "#Now add interactions upto user specified order\n",
    "poly_terms = PolynomialFeatures(degree = (2,4), include_bias=False)\n",
    "poly_terms.fit(jtpa_features_augmented)\n",
    "jtpa_features_polyterms_colnames =poly_terms.get_feature_names_out(jtpa_features_augmented.columns)\n",
    "jtpa_features_polyterms = pd.DataFrame(poly_terms.fit_transform(jtpa_features_augmented), index = jtpa_keep.index)\n",
    "jtpa_features_polyterms.columns = jtpa_features_polyterms_colnames\n",
    "\n",
    "#Drop duplicated columns. Higher order interactions of binary variables will equal lower order interaction terms.\n",
    "jtpa_features_polyterms = jtpa_features_polyterms.loc[:, ~jtpa_features_polyterms.T.duplicated(keep = 'first')]\n",
    "\n",
    "#How many unique features do we end up with?\n",
    "print('original no. of features: ', jtpa_features_augmented.shape[1])\n",
    "print('Interactions and higher order terms: ', jtpa_features_polyterms.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>prevearn</th>\n",
       "      <th>bfeduca</th>\n",
       "      <th>assignmt_Control</th>\n",
       "      <th>assignmt_Treatment</th>\n",
       "      <th>sex_Female</th>\n",
       "      <th>sex_Male</th>\n",
       "      <th>married_Married</th>\n",
       "      <th>married_Not married</th>\n",
       "      <th>pbhous_No</th>\n",
       "      <th>pbhous_Yes</th>\n",
       "      <th>wkless13_Did not work</th>\n",
       "      <th>wkless13_Worked</th>\n",
       "      <th>recommended_training_OJT</th>\n",
       "      <th>recommended_training_classroom</th>\n",
       "      <th>recommended_training_other</th>\n",
       "      <th>prevearn_2</th>\n",
       "      <th>prevearn_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300001</th>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  prevearn  bfeduca  assignmt_Control  assignmt_Treatment  \\\n",
       "recid                                                                  \n",
       "300001   46       0.0     12.0                 0                   1   \n",
       "\n",
       "        sex_Female  sex_Male  married_Married  married_Not married  pbhous_No  \\\n",
       "recid                                                                           \n",
       "300001           1         0                0                    1          1   \n",
       "\n",
       "        pbhous_Yes  wkless13_Did not work  wkless13_Worked  \\\n",
       "recid                                                        \n",
       "300001           0                      0                1   \n",
       "\n",
       "        recommended_training_OJT  recommended_training_classroom  \\\n",
       "recid                                                              \n",
       "300001                         0                               0   \n",
       "\n",
       "        recommended_training_other  prevearn_2  prevearn_3  \n",
       "recid                                                       \n",
       "300001                           1         0.0         0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jtpa_features_augmented.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age^2</th>\n",
       "      <th>age prevearn</th>\n",
       "      <th>age bfeduca</th>\n",
       "      <th>age assignmt_Control</th>\n",
       "      <th>age assignmt_Treatment</th>\n",
       "      <th>age sex_Female</th>\n",
       "      <th>age sex_Male</th>\n",
       "      <th>age married_Married</th>\n",
       "      <th>age married_Not married</th>\n",
       "      <th>age pbhous_No</th>\n",
       "      <th>age pbhous_Yes</th>\n",
       "      <th>age wkless13_Did not work</th>\n",
       "      <th>age wkless13_Worked</th>\n",
       "      <th>age recommended_training_OJT</th>\n",
       "      <th>age recommended_training_classroom</th>\n",
       "      <th>age recommended_training_other</th>\n",
       "      <th>age prevearn_2</th>\n",
       "      <th>age prevearn_3</th>\n",
       "      <th>prevearn^2</th>\n",
       "      <th>prevearn bfeduca</th>\n",
       "      <th>prevearn assignmt_Control</th>\n",
       "      <th>prevearn assignmt_Treatment</th>\n",
       "      <th>prevearn sex_Female</th>\n",
       "      <th>prevearn sex_Male</th>\n",
       "      <th>prevearn married_Married</th>\n",
       "      <th>prevearn married_Not married</th>\n",
       "      <th>prevearn pbhous_No</th>\n",
       "      <th>prevearn pbhous_Yes</th>\n",
       "      <th>prevearn wkless13_Did not work</th>\n",
       "      <th>prevearn wkless13_Worked</th>\n",
       "      <th>prevearn recommended_training_OJT</th>\n",
       "      <th>prevearn recommended_training_classroom</th>\n",
       "      <th>prevearn recommended_training_other</th>\n",
       "      <th>prevearn prevearn_2</th>\n",
       "      <th>prevearn prevearn_3</th>\n",
       "      <th>bfeduca^2</th>\n",
       "      <th>bfeduca assignmt_Control</th>\n",
       "      <th>bfeduca assignmt_Treatment</th>\n",
       "      <th>bfeduca sex_Female</th>\n",
       "      <th>bfeduca sex_Male</th>\n",
       "      <th>bfeduca married_Married</th>\n",
       "      <th>bfeduca married_Not married</th>\n",
       "      <th>bfeduca pbhous_No</th>\n",
       "      <th>bfeduca pbhous_Yes</th>\n",
       "      <th>bfeduca wkless13_Did not work</th>\n",
       "      <th>bfeduca wkless13_Worked</th>\n",
       "      <th>bfeduca recommended_training_OJT</th>\n",
       "      <th>bfeduca recommended_training_classroom</th>\n",
       "      <th>bfeduca recommended_training_other</th>\n",
       "      <th>bfeduca prevearn_2</th>\n",
       "      <th>...</th>\n",
       "      <th>pbhous_Yes recommended_training_other prevearn_2^2</th>\n",
       "      <th>pbhous_Yes recommended_training_other prevearn_2 prevearn_3</th>\n",
       "      <th>pbhous_Yes recommended_training_other prevearn_3^2</th>\n",
       "      <th>pbhous_Yes prevearn_2^3</th>\n",
       "      <th>pbhous_Yes prevearn_2^2 prevearn_3</th>\n",
       "      <th>pbhous_Yes prevearn_2 prevearn_3^2</th>\n",
       "      <th>pbhous_Yes prevearn_3^3</th>\n",
       "      <th>wkless13_Did not work recommended_training_OJT prevearn_2^2</th>\n",
       "      <th>wkless13_Did not work recommended_training_OJT prevearn_2 prevearn_3</th>\n",
       "      <th>wkless13_Did not work recommended_training_OJT prevearn_3^2</th>\n",
       "      <th>wkless13_Did not work recommended_training_classroom prevearn_2^2</th>\n",
       "      <th>wkless13_Did not work recommended_training_classroom prevearn_2 prevearn_3</th>\n",
       "      <th>wkless13_Did not work recommended_training_classroom prevearn_3^2</th>\n",
       "      <th>wkless13_Did not work recommended_training_other prevearn_2^2</th>\n",
       "      <th>wkless13_Did not work recommended_training_other prevearn_2 prevearn_3</th>\n",
       "      <th>wkless13_Did not work recommended_training_other prevearn_3^2</th>\n",
       "      <th>wkless13_Did not work prevearn_2^3</th>\n",
       "      <th>wkless13_Did not work prevearn_2^2 prevearn_3</th>\n",
       "      <th>wkless13_Did not work prevearn_2 prevearn_3^2</th>\n",
       "      <th>wkless13_Did not work prevearn_3^3</th>\n",
       "      <th>wkless13_Worked recommended_training_OJT prevearn_2^2</th>\n",
       "      <th>wkless13_Worked recommended_training_OJT prevearn_2 prevearn_3</th>\n",
       "      <th>wkless13_Worked recommended_training_OJT prevearn_3^2</th>\n",
       "      <th>wkless13_Worked recommended_training_classroom prevearn_2^2</th>\n",
       "      <th>wkless13_Worked recommended_training_classroom prevearn_2 prevearn_3</th>\n",
       "      <th>wkless13_Worked recommended_training_classroom prevearn_3^2</th>\n",
       "      <th>wkless13_Worked recommended_training_other prevearn_2^2</th>\n",
       "      <th>wkless13_Worked recommended_training_other prevearn_2 prevearn_3</th>\n",
       "      <th>wkless13_Worked recommended_training_other prevearn_3^2</th>\n",
       "      <th>wkless13_Worked prevearn_2^3</th>\n",
       "      <th>wkless13_Worked prevearn_2^2 prevearn_3</th>\n",
       "      <th>wkless13_Worked prevearn_2 prevearn_3^2</th>\n",
       "      <th>wkless13_Worked prevearn_3^3</th>\n",
       "      <th>recommended_training_OJT prevearn_2^3</th>\n",
       "      <th>recommended_training_OJT prevearn_2^2 prevearn_3</th>\n",
       "      <th>recommended_training_OJT prevearn_2 prevearn_3^2</th>\n",
       "      <th>recommended_training_OJT prevearn_3^3</th>\n",
       "      <th>recommended_training_classroom prevearn_2^3</th>\n",
       "      <th>recommended_training_classroom prevearn_2^2 prevearn_3</th>\n",
       "      <th>recommended_training_classroom prevearn_2 prevearn_3^2</th>\n",
       "      <th>recommended_training_classroom prevearn_3^3</th>\n",
       "      <th>recommended_training_other prevearn_2^3</th>\n",
       "      <th>recommended_training_other prevearn_2^2 prevearn_3</th>\n",
       "      <th>recommended_training_other prevearn_2 prevearn_3^2</th>\n",
       "      <th>recommended_training_other prevearn_3^3</th>\n",
       "      <th>prevearn_2^4</th>\n",
       "      <th>prevearn_2^3 prevearn_3</th>\n",
       "      <th>prevearn_2^2 prevearn_3^2</th>\n",
       "      <th>prevearn_2 prevearn_3^3</th>\n",
       "      <th>prevearn_3^4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300001</th>\n",
       "      <td>2116.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 3725 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         age^2  age prevearn  age bfeduca  age assignmt_Control  \\\n",
       "recid                                                             \n",
       "300001  2116.0           0.0        552.0                   0.0   \n",
       "\n",
       "        age assignmt_Treatment  age sex_Female  age sex_Male  \\\n",
       "recid                                                          \n",
       "300001                    46.0            46.0           0.0   \n",
       "\n",
       "        age married_Married  age married_Not married  age pbhous_No  \\\n",
       "recid                                                                 \n",
       "300001                  0.0                     46.0           46.0   \n",
       "\n",
       "        age pbhous_Yes  age wkless13_Did not work  age wkless13_Worked  \\\n",
       "recid                                                                    \n",
       "300001             0.0                        0.0                 46.0   \n",
       "\n",
       "        age recommended_training_OJT  age recommended_training_classroom  \\\n",
       "recid                                                                      \n",
       "300001                           0.0                                 0.0   \n",
       "\n",
       "        age recommended_training_other  age prevearn_2  age prevearn_3  \\\n",
       "recid                                                                    \n",
       "300001                            46.0             0.0             0.0   \n",
       "\n",
       "        prevearn^2  prevearn bfeduca  prevearn assignmt_Control  \\\n",
       "recid                                                             \n",
       "300001         0.0               0.0                        0.0   \n",
       "\n",
       "        prevearn assignmt_Treatment  prevearn sex_Female  prevearn sex_Male  \\\n",
       "recid                                                                         \n",
       "300001                          0.0                  0.0                0.0   \n",
       "\n",
       "        prevearn married_Married  prevearn married_Not married  \\\n",
       "recid                                                            \n",
       "300001                       0.0                           0.0   \n",
       "\n",
       "        prevearn pbhous_No  prevearn pbhous_Yes  \\\n",
       "recid                                             \n",
       "300001                 0.0                  0.0   \n",
       "\n",
       "        prevearn wkless13_Did not work  prevearn wkless13_Worked  \\\n",
       "recid                                                              \n",
       "300001                             0.0                       0.0   \n",
       "\n",
       "        prevearn recommended_training_OJT  \\\n",
       "recid                                       \n",
       "300001                                0.0   \n",
       "\n",
       "        prevearn recommended_training_classroom  \\\n",
       "recid                                             \n",
       "300001                                      0.0   \n",
       "\n",
       "        prevearn recommended_training_other  prevearn prevearn_2  \\\n",
       "recid                                                              \n",
       "300001                                  0.0                  0.0   \n",
       "\n",
       "        prevearn prevearn_3  bfeduca^2  bfeduca assignmt_Control  \\\n",
       "recid                                                              \n",
       "300001                  0.0      144.0                       0.0   \n",
       "\n",
       "        bfeduca assignmt_Treatment  bfeduca sex_Female  bfeduca sex_Male  \\\n",
       "recid                                                                      \n",
       "300001                        12.0                12.0               0.0   \n",
       "\n",
       "        bfeduca married_Married  bfeduca married_Not married  \\\n",
       "recid                                                          \n",
       "300001                      0.0                         12.0   \n",
       "\n",
       "        bfeduca pbhous_No  bfeduca pbhous_Yes  bfeduca wkless13_Did not work  \\\n",
       "recid                                                                          \n",
       "300001               12.0                 0.0                            0.0   \n",
       "\n",
       "        bfeduca wkless13_Worked  bfeduca recommended_training_OJT  \\\n",
       "recid                                                               \n",
       "300001                     12.0                               0.0   \n",
       "\n",
       "        bfeduca recommended_training_classroom  \\\n",
       "recid                                            \n",
       "300001                                     0.0   \n",
       "\n",
       "        bfeduca recommended_training_other  bfeduca prevearn_2  ...  \\\n",
       "recid                                                           ...   \n",
       "300001                                12.0                 0.0  ...   \n",
       "\n",
       "        pbhous_Yes recommended_training_other prevearn_2^2  \\\n",
       "recid                                                        \n",
       "300001                                                0.0    \n",
       "\n",
       "        pbhous_Yes recommended_training_other prevearn_2 prevearn_3  \\\n",
       "recid                                                                 \n",
       "300001                                                0.0             \n",
       "\n",
       "        pbhous_Yes recommended_training_other prevearn_3^2  \\\n",
       "recid                                                        \n",
       "300001                                                0.0    \n",
       "\n",
       "        pbhous_Yes prevearn_2^3  pbhous_Yes prevearn_2^2 prevearn_3  \\\n",
       "recid                                                                 \n",
       "300001                      0.0                                 0.0   \n",
       "\n",
       "        pbhous_Yes prevearn_2 prevearn_3^2  pbhous_Yes prevearn_3^3  \\\n",
       "recid                                                                 \n",
       "300001                                 0.0                      0.0   \n",
       "\n",
       "        wkless13_Did not work recommended_training_OJT prevearn_2^2  \\\n",
       "recid                                                                 \n",
       "300001                                                0.0             \n",
       "\n",
       "        wkless13_Did not work recommended_training_OJT prevearn_2 prevearn_3  \\\n",
       "recid                                                                          \n",
       "300001                                                0.0                      \n",
       "\n",
       "        wkless13_Did not work recommended_training_OJT prevearn_3^2  \\\n",
       "recid                                                                 \n",
       "300001                                                0.0             \n",
       "\n",
       "        wkless13_Did not work recommended_training_classroom prevearn_2^2  \\\n",
       "recid                                                                       \n",
       "300001                                                0.0                   \n",
       "\n",
       "        wkless13_Did not work recommended_training_classroom prevearn_2 prevearn_3  \\\n",
       "recid                                                                                \n",
       "300001                                                0.0                            \n",
       "\n",
       "        wkless13_Did not work recommended_training_classroom prevearn_3^2  \\\n",
       "recid                                                                       \n",
       "300001                                                0.0                   \n",
       "\n",
       "        wkless13_Did not work recommended_training_other prevearn_2^2  \\\n",
       "recid                                                                   \n",
       "300001                                                0.0               \n",
       "\n",
       "        wkless13_Did not work recommended_training_other prevearn_2 prevearn_3  \\\n",
       "recid                                                                            \n",
       "300001                                                0.0                        \n",
       "\n",
       "        wkless13_Did not work recommended_training_other prevearn_3^2  \\\n",
       "recid                                                                   \n",
       "300001                                                0.0               \n",
       "\n",
       "        wkless13_Did not work prevearn_2^3  \\\n",
       "recid                                        \n",
       "300001                                 0.0   \n",
       "\n",
       "        wkless13_Did not work prevearn_2^2 prevearn_3  \\\n",
       "recid                                                   \n",
       "300001                                            0.0   \n",
       "\n",
       "        wkless13_Did not work prevearn_2 prevearn_3^2  \\\n",
       "recid                                                   \n",
       "300001                                            0.0   \n",
       "\n",
       "        wkless13_Did not work prevearn_3^3  \\\n",
       "recid                                        \n",
       "300001                                 0.0   \n",
       "\n",
       "        wkless13_Worked recommended_training_OJT prevearn_2^2  \\\n",
       "recid                                                           \n",
       "300001                                                0.0       \n",
       "\n",
       "        wkless13_Worked recommended_training_OJT prevearn_2 prevearn_3  \\\n",
       "recid                                                                    \n",
       "300001                                                0.0                \n",
       "\n",
       "        wkless13_Worked recommended_training_OJT prevearn_3^2  \\\n",
       "recid                                                           \n",
       "300001                                                0.0       \n",
       "\n",
       "        wkless13_Worked recommended_training_classroom prevearn_2^2  \\\n",
       "recid                                                                 \n",
       "300001                                                0.0             \n",
       "\n",
       "        wkless13_Worked recommended_training_classroom prevearn_2 prevearn_3  \\\n",
       "recid                                                                          \n",
       "300001                                                0.0                      \n",
       "\n",
       "        wkless13_Worked recommended_training_classroom prevearn_3^2  \\\n",
       "recid                                                                 \n",
       "300001                                                0.0             \n",
       "\n",
       "        wkless13_Worked recommended_training_other prevearn_2^2  \\\n",
       "recid                                                             \n",
       "300001                                                0.0         \n",
       "\n",
       "        wkless13_Worked recommended_training_other prevearn_2 prevearn_3  \\\n",
       "recid                                                                      \n",
       "300001                                                0.0                  \n",
       "\n",
       "        wkless13_Worked recommended_training_other prevearn_3^2  \\\n",
       "recid                                                             \n",
       "300001                                                0.0         \n",
       "\n",
       "        wkless13_Worked prevearn_2^3  wkless13_Worked prevearn_2^2 prevearn_3  \\\n",
       "recid                                                                           \n",
       "300001                           0.0                                      0.0   \n",
       "\n",
       "        wkless13_Worked prevearn_2 prevearn_3^2  wkless13_Worked prevearn_3^3  \\\n",
       "recid                                                                           \n",
       "300001                                      0.0                           0.0   \n",
       "\n",
       "        recommended_training_OJT prevearn_2^3  \\\n",
       "recid                                           \n",
       "300001                                    0.0   \n",
       "\n",
       "        recommended_training_OJT prevearn_2^2 prevearn_3  \\\n",
       "recid                                                      \n",
       "300001                                               0.0   \n",
       "\n",
       "        recommended_training_OJT prevearn_2 prevearn_3^2  \\\n",
       "recid                                                      \n",
       "300001                                               0.0   \n",
       "\n",
       "        recommended_training_OJT prevearn_3^3  \\\n",
       "recid                                           \n",
       "300001                                    0.0   \n",
       "\n",
       "        recommended_training_classroom prevearn_2^3  \\\n",
       "recid                                                 \n",
       "300001                                          0.0   \n",
       "\n",
       "        recommended_training_classroom prevearn_2^2 prevearn_3  \\\n",
       "recid                                                            \n",
       "300001                                                0.0        \n",
       "\n",
       "        recommended_training_classroom prevearn_2 prevearn_3^2  \\\n",
       "recid                                                            \n",
       "300001                                                0.0        \n",
       "\n",
       "        recommended_training_classroom prevearn_3^3  \\\n",
       "recid                                                 \n",
       "300001                                          0.0   \n",
       "\n",
       "        recommended_training_other prevearn_2^3  \\\n",
       "recid                                             \n",
       "300001                                      0.0   \n",
       "\n",
       "        recommended_training_other prevearn_2^2 prevearn_3  \\\n",
       "recid                                                        \n",
       "300001                                                0.0    \n",
       "\n",
       "        recommended_training_other prevearn_2 prevearn_3^2  \\\n",
       "recid                                                        \n",
       "300001                                                0.0    \n",
       "\n",
       "        recommended_training_other prevearn_3^3  prevearn_2^4  \\\n",
       "recid                                                           \n",
       "300001                                      0.0           0.0   \n",
       "\n",
       "        prevearn_2^3 prevearn_3  prevearn_2^2 prevearn_3^2  \\\n",
       "recid                                                        \n",
       "300001                      0.0                        0.0   \n",
       "\n",
       "        prevearn_2 prevearn_3^3  prevearn_3^4  \n",
       "recid                                          \n",
       "300001                      0.0           0.0  \n",
       "\n",
       "[1 rows x 3725 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jtpa_features_polyterms.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9041, 3743)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Full set of features\n",
    "jtpa_features = jtpa_features_augmented.merge(jtpa_features_polyterms, on = 'recid')\n",
    "jtpa_features.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Some Descriptive Statistics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continuing, it is useful to see how agents were assigned to the treatment/control arms. The following table shows how applicants were assigned to treatment and control, by an applicant's sex (`= 1` if Male). The variable `assignmt` equals `1` if the applicant was assigned to the treatment arm, and the variable `recommended_training` displays the recommended training (recall that this decision was made by a case worker *prior to assignment*).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>recommended_training</th>\n",
       "      <th colspan=\"2\" halign=\"left\">OJT</th>\n",
       "      <th colspan=\"2\" halign=\"left\">classroom</th>\n",
       "      <th colspan=\"2\" halign=\"left\">other</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assignmt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Control</th>\n",
       "      <td>630</td>\n",
       "      <td>720</td>\n",
       "      <td>634</td>\n",
       "      <td>278</td>\n",
       "      <td>339</td>\n",
       "      <td>416</td>\n",
       "      <td>3017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Treatment</th>\n",
       "      <td>1198</td>\n",
       "      <td>1447</td>\n",
       "      <td>1248</td>\n",
       "      <td>607</td>\n",
       "      <td>765</td>\n",
       "      <td>759</td>\n",
       "      <td>6024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1828</td>\n",
       "      <td>2167</td>\n",
       "      <td>1882</td>\n",
       "      <td>885</td>\n",
       "      <td>1104</td>\n",
       "      <td>1175</td>\n",
       "      <td>9041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "recommended_training    OJT       classroom       other         All\n",
       "sex                  Female  Male    Female Male Female  Male      \n",
       "assignmt                                                           \n",
       "Control                 630   720       634  278    339   416  3017\n",
       "Treatment              1198  1447      1248  607    765   759  6024\n",
       "All                    1828  2167      1882  885   1104  1175  9041"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assigned_table = pd.crosstab(index = jtpa_keep.assignmt, \n",
    "                            columns = [jtpa_keep.recommended_training, jtpa_keep.sex] , margins = True)\n",
    "assigned_table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure shows the distribution of income prior to assignment, split by an applicant's sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.violinplot(data = jtpa_keep, \n",
    "                x = 'prevearn',\n",
    "                y = 'sex',\n",
    "                hue = 'sex')\n",
    "plt.legend(loc='center right')\n",
    "plt.xlim(-3, 20)\n",
    "plt.xlabel('Earnings in year prior to assignment.')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimating Conditional Means"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first estimate the conditional mean functions $\\hat{\\mu}_d$ for all values of $d$ (including $d=0$). Estimated values $\\hat{\\mu}_d$ are saved and exported."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross Fitting Procedure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions implements the cross fitting routine described above. It requires a dictionary of model pipelines - each element corresponding to a particular regression algorithm - and a dictionary of model hyperparameters. The number of data folds must be set as well. The function then fits the best model out of the candidates considered and outputs predicted values for a given set of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_fit_regression(X, y, obs, model_pipelines, model_hyperparameters, folds =2, r_state = 123, show_progress = False):\n",
    "\n",
    "    pred = np.zeros((len(y), 1))\n",
    "    #Initialize data splitting:\n",
    "    kf = KFold(n_splits = folds)\n",
    "    #For each fold, fit model and return predicted outcome.\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        feature_data, outcome_data = X.iloc[train_index, :][obs.iloc[train_index]], y.iloc[train_index][obs.iloc[train_index]]\n",
    "        (X_train, X_test, y_train, y_test) = train_test_split(feature_data, outcome_data, test_size=0.2, random_state = r_state)\n",
    "        fitted_models = {}\n",
    "        for name, pipeline in model_pipelines.items():\n",
    "            model = GridSearchCV(pipeline, model_hyperparameters[name], cv = 2, n_jobs = -1)\n",
    "            model.fit(X_train, y_train)\n",
    "            fitted_models[name] = model\n",
    "            if show_progress:\n",
    "                print('For fold {}, model {} fitted.'.format(i, name))\n",
    "\n",
    "        #Choose the best model\n",
    "        #First initialize sample prediction error\n",
    "        pred_error = {}\n",
    "        #Calculate prediction error for each model.\n",
    "        for name, model in fitted_models.items():\n",
    "            model_pred = model.predict(X_test)\n",
    "            model_error = r2_score(y_test, model_pred)\n",
    "            pred_error[name] = model_error\n",
    "        #Predicted values from best model\n",
    "        best_model = np.array(list(pred_error.keys()))[list(pred_error.values()) == max(list(pred_error.values()))][0]\n",
    "        pred[test_index, :] = fitted_models[best_model].predict(X.iloc[test_index, :]).reshape(-1,1) \n",
    "        if show_progress:\n",
    "            print('Predicted values for fold {} derived.'.format(i))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make pipelines for regression estimation\n",
    "pipelines_regression = {\n",
    "    'lasso' : make_pipeline(StandardScaler(), Lasso(random_state=123)),\n",
    "    'ridge' : make_pipeline(StandardScaler(), Ridge(random_state=123)),\n",
    "    'enet' : make_pipeline(StandardScaler(), ElasticNet(random_state = 123)),\n",
    "    'rf' : make_pipeline(StandardScaler(), RandomForestRegressor(random_state=123))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso hyperparameters\n",
    "lasso_hyperparameters = { \n",
    "    'lasso__alpha' : [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10] \n",
    "}\n",
    "\n",
    "# Ridge hyperparameters\n",
    "ridge_hyperparameters = { \n",
    "    'ridge__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10]  \n",
    "}\n",
    "# Elastic Net hyperparameters\n",
    "enet_hyperparameters = { \n",
    "    'elasticnet__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10],                        \n",
    "    'elasticnet__l1_ratio' : [0.1, 0.3, 0.5, 0.7, 0.9]  \n",
    "}\n",
    "#Random Forest Regressor hyperparameters\n",
    "rfr_hyperparameters = {'randomforestregressor__n_estimators': [100, 200],\n",
    "                    'randomforestregressor__max_features': ['sqrt', 0.33]\n",
    "                    }\n",
    "#Gradient Boosted Regressor hyperparameters\n",
    "gbr_hyperparameters = {'gradientboostingregressor__n_estimators': [100, 200],\n",
    "                        'gradientboostingregressor__learning_rate': [0.05, 0.1, 0.2],\n",
    "                        'gradientboostingregressor__max_depth': [1, 3, 5]}\n",
    "                        \n",
    "# Create hyperparameters dictionary\n",
    "hyperparameters_regression = {\n",
    "    'lasso' : lasso_hyperparameters,\n",
    "    'ridge' : ridge_hyperparameters,\n",
    "    'enet' : enet_hyperparameters,\n",
    "    'rf' : rfr_hyperparameters\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block estimates the conditional mean functions and exports the estimated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment arm: classroom,  obs.:  1855\n",
      "Estimation completed for treatment arm: classroom.\n",
      "Treatment arm: OJT,  obs.:  2645\n",
      "Estimation completed for treatment arm: OJT.\n",
      "Treatment arm: other,  obs.:  1524\n",
      "Estimation completed for treatment arm: other.\n",
      "Treatment arm: control,  obs.:  3017\n",
      "Estimation completed for treatment arm: control.\n"
     ]
    }
   ],
   "source": [
    "for d in ['classroom', 'OJT', 'other', 'control']:\n",
    "    if d == 'control':\n",
    "        obs = (jtpa_keep.assignmt=='Control')\n",
    "        print('Treatment arm: {}, '.format(d), 'obs.: ', obs.sum())\n",
    "    else:\n",
    "        obs = (jtpa_keep.assignmt=='Treatment')&(jtpa_keep.recommended_training==d)\n",
    "        print('Treatment arm: {}, '.format(d), 'obs.: ', obs.sum())\n",
    "\n",
    "    predicted_outcome = cross_fit_regression(X = jtpa_features, y= jtpa_keep.earnings,\n",
    "                                            obs = obs, \n",
    "                                            model_pipelines = pipelines_regression, \n",
    "                                            model_hyperparameters = hyperparameters_regression,\n",
    "                                            folds= 5)\n",
    "    results = pd.DataFrame(predicted_outcome, columns = ['pred_earnings'], index = jtpa_keep.index)\n",
    "\n",
    "    #Add estimated outcome to dataset.\n",
    "    jtpa_keep = jtpa_keep.join(results, on = 'recid')\n",
    "    results.to_csv(str('pred_earnings_{}.csv'.format(d)))\n",
    "    print('Estimation completed for treatment arm: {}.'.format(d))\n",
    "\n",
    "#Export the dataset with predicted mean values.\n",
    "jtpa_keep.to_csv('data_with_pred_outcomes.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimating Conditional Probabilities"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conditional probability functions $\\hat{p}_d$ must satisfy the propoerties of a probability distribution function. Namely, \n",
    "\\begin{align}\n",
    "& 0\\leq \\hat{p}_d(x)\\leq 1 \\hspace{3mm}\\text{for all values $x$},\\\\\n",
    "& \\sum_{d}\\hat{p}_d(x) = 1\\hspace{3mm}\\text{for all values $x$.}\n",
    "\\end{align}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross Fitting Procedure for Conditional Probability Estimation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function implements the cross fitted estimation routine, but for when conditional probabilities must be estimated. It is very similar to `cross_fit_regression()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_fit_classification(X, y, model_pipelines, model_hyperparameters, folds =2, r_state = 123, show_progress = False):\n",
    "\n",
    "    pred = np.zeros((len(y), 4))\n",
    "    #Initialize data splitting:\n",
    "    kf = KFold(n_splits = folds)\n",
    "    #For each fold, fit model and return predicted outcome.\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        feature_data, outcome_data = X.iloc[train_index, :], y.iloc[train_index]\n",
    "        (X_train, X_test, y_train, y_test) = train_test_split(feature_data, outcome_data, test_size=0.2, random_state = r_state)\n",
    "        fitted_models = {}\n",
    "        for name, pipeline in model_pipelines.items():\n",
    "            model = GridSearchCV(pipeline, model_hyperparameters[name], cv = 2, n_jobs = -1)\n",
    "            model.fit(X_train, y_train)\n",
    "            fitted_models[name] = model\n",
    "            if show_progress:\n",
    "                print('For fold {}, model {} fitted.'.format(i, name))\n",
    "\n",
    "        #Choose the best model\n",
    "        #First initialize sample prediction error\n",
    "        pred_error = {}\n",
    "        #Calculate prediction error for each model.\n",
    "        for name, model in fitted_models.items():\n",
    "            model_pred = model.predict(X_test)\n",
    "            model_error = accuracy_score(y_test, model_pred)\n",
    "            pred_error[name] = model_error\n",
    "        #Predicted values from best model\n",
    "        best_model = np.array(list(pred_error.keys()))[list(pred_error.values()) == max(list(pred_error.values()))][0]\n",
    "        pred[test_index, :] = fitted_models[best_model].predict_proba(X.iloc[test_index, :]).reshape(-1,1) \n",
    "        if show_progress:\n",
    "            print('Predicted values for fold {} derived.'.format(i))\n",
    "    return pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a5413b02e73a67dd7695e313a7e994180bddd3fbd0043632d809ce449d80802"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
